from pyroomacoustics import room as pra
from glob import glob
from pathlib import Path
import numpy as np
import os
import pandas as pd
from time import time
from torchaudio import load
from torchaudio.functional import resample
from torch_audiomentations import Compose, PitchShift

file = "step2_prepare_training_sources/data/cicada_song/segments_preprocessed/aburazemi/Aburazemi_01_01.wav"
def load_audio(file, sr_to=48000):
    s, sr = load(file)
    if s.max() < 1: # if float, convert to int16
        s = s * 2**16
    s = resample(s, sr, sr_to)
    return s

def softmax(x):
    x = x - np.max(x, axis=0)
    return np.exp(x) / np.sum(np.exp(x), axis=0)

def get_audio_datasets(cicada_dir, bg_dir, others_dir):
    """
    Get dataframes of cicada, background, and other audio files.
    For cicada and other audio files, the dataframe contains the file path (`file`) and the label (`label`).
    For background audio files, the dataframe only contains the file path.
    Parameters
    ----------
    cicada_dir : str
        Directory containing cicada audio files.
        The directory should have subdirectories for each species.
    bg_dir : str
        Directory containing background audio files.
    others_dir : str
        Directory containing other audio files.
        The directory should have subdirectories for each category.
    Returns
    -------
    cicadas : pd.DataFrame
        Dataframe containing cicada audio files.
        Contains `file` and `label` columns.
    bgs : pd.DataFrame
        Dataframe containing background audio files.
        Contains `file` column.
    others : pd.DataFrame
        Dataframe containing other audio files.
        Contains `file` and `label` columns.
    """
    cicadas = pd.DataFrame({
        "file": glob(f"{cicada_dir}/**/*.wav")
    })
    cicadas["label"] = cicadas.file.apply(lambda x: Path(x).parent.name)

    others = pd.DataFrame({
        "file": glob(f"{others_dir}/**/*.wav")
    })
    others["label"] = others.file.apply(lambda x: Path(x).parent.name)

    bgs = pd.DataFrame({
        "file": glob(f"{bg_dir}/*.wav")
    })
    return cicadas, bgs, others

def add_sound_sources(room, sound_df, audiomentation, species_range, weights, popsize_range, distance_range, device="cpu"):
    """
    Add sound sources to the room.
    Parameters
    ----------
    room : pyroomacoustics.room.Room
        Room object to add sound sources.
    sound_df : pd.DataFrame
        Dataframe containing sound files.
        The dataframe should contain `file` and `label` columns.
        Usually generated by get_audio_datasets().
    audiomentation : audiomentations.Compose
        Audiomentation object to augment the sound.
        If None, no augmentation will be applied.
    species_range : list
        Range of the number of species (categories) to use.
    weights : dict
        Weights of species to use.
        The keys are species names and the values are weights.
        Higher weights mean higher probability to be selected.
    popsize_range : list
        Range of the number of sound sources.
    distance_range : list
        Range of the distance between sound sources and the microphone.
    Returns
    -------
    sps : list
        List of species.
    starts : list
        List of start time.
    ends : list
        List of end time.
    distances : list
        List of distance from the microphone.
    """
    # Number of species (categories) to use
    np.random.seed()
    n_species = np.random.randint(min(species_range), max(species_range) + 1)
    # Which species to use
    species = np.random.choice(list(weights.keys()), n_species, p=softmax(np.array(list(weights.values()))), replace=False)
    # Population size
    popsize = np.random.randint(min(popsize_range), max(popsize_range) + 1)
    # Weights of species to use
    species_weights = {k: v for k, v in weights.items() if k in species}
    sps = [] # To store species
    starts = [] # To store start time
    distances = [] # To store distance from the microphone
    ends = [] # To store end time
    
    # Add sound sources to the room
    t1s = 0
    t2s = 0
    t3s = 0
    t4s = 0
    for _ in range(popsize):
        t0 = time()
        sp = np.random.choice(species, 1, p=softmax(np.array(list(species_weights.values()))))
        song_data = sound_df[sound_df["label"]==sp[0]].sample()
        sps.append(song_data["label"].values[0])
        song = np.zeros(room.sources[0].signal.shape)
        s = load_audio(song_data["file"].values[0], sr_to=room.fs)
        t1 = time()
        if audiomentation is not None:
            s = audiomentation(s.to(device).unsqueeze(0)).cpu().numpy()[0][0]
        else:
            s = s.cpu().numpy()[0]
        t2 = time()
        # Distance from the microphone
        dist = np.random.randint(min(distance_range), max(distance_range))
        distances.append(dist)
        # Add sound source to the room
        # If the sound is longer than the room.sources[0].signal, cut it out.
        if len(s) > len(song):
            start = np.random.randint(0, len(s) - len(song))
            end = start + len(song)
            starts.append(0)
            ends.append(len(song))
            s = s[start:end]
            song += s
        elif len(s) == len(song):
            starts.append(0)
            ends.append(len(song))
            song += s
        # If the sound is shorter than the room.sources[0].signal, place it at a random position.
        else:
            start = np.random.randint(0, len(song) - len(s))
            end = start + len(s)
            starts.append(start)
            ends.append(end)
            song[start:end] += s
        t3 = time()
        room.add_source([0,dist], song)
        t4 = time()
        t1s += t1 - t0
        t2s += t2 - t1
        t3s += t3 - t2
        t4s += t4 - t3
    # print(f"Time: {np.mean(t1s):.2f}s (load: {np.mean(t1s):.2f}s, augment: {np.mean(t2s):.2f}s, add: {np.mean(t3s):.2f}s, add_source: {np.mean(t4s):.2f}s)")
    return sps, starts, ends, distances

def generate(wav_path, label_path, cicadas, bgs, others, sr = 48000, audio_sec = 30, category_ratio = [0.7, 0.3],
            # Cicadas
            cicadas_to_use = ["aburazemi", "higurashi", "minminzemi", "niiniizemi", "tsukutsukuboushi"],
            cicada_weights = {"aburazemi": 1, "higurashi": 1, "minminzemi": 1,
                                "niiniizemi": 1, "tsukutsukuboushi": 1, },
            cicada_popsize_range = [1, 20],
            cicada_distance_range = [10, 60],
            cicada_species_range = [1, 4],
            # Other sounds
            others_weights = {"birds": 1, "esc50": 1, "insects": 1},
            others_popsize_range = [1, 20],
            others_distance_range = [10, 60],
            others_species_range = [1, 4],
            pitch_shift_range = None,
            device="cpu"
        ):
    """
    Generate a simulated cicada chorus data.
    Parameters
    ----------
    wav_path : str
        Path to save the generated audio.
    label_path : str
        Path to save the generated label.
        Label file will be generated as audacity label file format.
    cicadas : pd.DataFrame
        Dataframe containing cicada audio files. Generated by get_audio_datasets().
    bgs : pd.DataFrame
        Dataframe containing background audio files. Generated by get_audio_datasets().
    others : pd.DataFrame
        Dataframe containing other audio files. Generated by get_audio_datasets().
    sr : int
        Sampling rate of the generated audio.
    audio_sec : int
        Length of generated audio in seconds.
    category_ratio : list
        Ratio of with_cicada and without_cicada.
        If the ratio is [0.7, 0.3], 70% of the generated audio will contain cicada sound.
    cicadas_to_use : list
        List of cicada species to use.
    cicada_weights : dict
        Weights of cicada species. The keys are species names and the values are weights.
        Higher weights mean higher probability to be selected.
    cicada_popsize_range : list
        Range of the number of cicadas.
    cicada_distance_range : list
        Range of the distance between cicadas and microphone.
    cicada_species_range : list
        Range of the number of cicada species.
    others_weights : dict
        Weights of other sounds.
    others_popsize_range : list
        Range of the number of other sounds.
    others_distance_range : list
        Range of the distance between other sounds and microphone.
    others_species_range : list
        Range of the number of other sounds.
    pitch_shift_range : list
        Range of pitch shift. If None, no pitch shift will be applied.
        Default is None since pitch shift consumes a lot of time.
    device : str
        Device to use for audio augmentation.
        If "cuda", audio augmentation will be faster.
        If "cpu", audio augmentation will be slower but you can run the whole process with multicores.
        If you do not use data augmentation, set it to "cpu".

    Returns
    -------
    None (The generated audio and label will be saved to the specified path.)
    """
    t0 = time()
    np.random.seed()
    # Setting audio augmentation
    if pitch_shift_range is not None:
        audiomentation = Compose([
            PitchShift(min_transpose_semitones=min(pitch_shift_range), max_transpose_semitones=max(pitch_shift_range), p=0.5, sample_rate=sr),
        ])
    else:
        audiomentation = None
    # Setting room
    # ----------------------------------------
    room = pra.AnechoicRoom(
        dim=2, # 2D
        fs=sr,
        sigma2_awgn=100,
        temperature=30,
        humidity=70,
        air_absorption=True
    )
    # Add microphone at the center of the room
    room.add_microphone(loc=[0, 0])
    # Randomly select category with specified ratio
    category = np.random.choice(["with_cicada", "without_cicada"], p=category_ratio)

    # Background sound
    # ----------------------------------------
    # Randomly select background sound
    bg = load_audio(bgs.sample()["file"].values[0], sr_to=sr)[0].numpy()
    # Cut out bg for audio_sec at a random position. If it is shorter than audio_sec, repeat bg until it becomes audio_sec.
    if len(bg) != sr * audio_sec:
        bg = bg[np.random.randint(0, len(bg) - sr * audio_sec):][:sr * audio_sec]
    # Place bg at the distance of 1m from the microphone
    room.add_source([0,1], bg)
    t1 = time()
    # Add sound sources
    # ----------------------------------------
    sps = []
    starts = []
    ends = []
    distances = []
    if category == "with_cicada":
        # Add cicada sound sources
        # Filter cicadas to use
        weights = {k: v for k, v in cicada_weights.items() if k in cicadas_to_use}
        _sps, _starts, _ends, _distances = add_sound_sources(room, cicadas, audiomentation, cicada_species_range,
                                                             weights, cicada_popsize_range, cicada_distance_range, device=device)
        sps += _sps
        starts += _starts
        ends += _ends
        distances += _distances
        # Add other sound sources
        _sps, _starts, _ends, _distances = add_sound_sources(room, others, audiomentation, others_species_range, 
                                                        others_weights, others_popsize_range, others_distance_range, device=device)
        sps += _sps
        starts += _starts
        ends += _ends
        distances += _distances
    elif category == "without_cicada":
        # Add other sound sources
        _sps, _starts, _ends, _distances = add_sound_sources(room, others, audiomentation, others_species_range, 
                                                        others_weights, others_popsize_range, others_distance_range, device=device)
        sps += _sps
        starts += _starts
        ends += _ends
        distances += _distances
    t2 = time()
    # Simulate room
    # ----------------------------------------
    premix = room.simulate(return_premix=True) # premix can be used for sound source separation
    t3 = time()
    # Save audio file
    # ----------------------------------------
    if not os.path.exists(Path(wav_path).parent):
        os.makedirs(Path(wav_path).parent, exist_ok=True)
    room.mic_array.to_wav(
        wav_path,
        bitdepth=np.int16,
    )
    # Save label file
    # ----------------------------------------
    if not os.path.exists(Path(label_path).parent):
        os.makedirs(Path(label_path).parent, exist_ok=True)
    if os.path.exists(label_path):
        os.remove(label_path)
    
    if len(sps) == 0:
        with open(label_path, mode='a') as f:
            f.write("")
    else:
        for sp, start,end, distance in zip(sps, starts, ends, distances):
            s = start / sr
            e = end / sr
            with open(label_path, mode='a') as f:
                f.write("{}\t{}\t{}\t{}\n".format(s, e, sp, distance))
    t4 = time()
    # print("----------------------------------------")
    # print(f"Time: {t4 - t0:.2f}s (bg: {t1 - t0:.2f}s, add_sources: {t2 - t1:.2f}s, simulate: {t3 - t2:.2f}s, save: {t4 - t3:.2f}s)")

cicadas, bgs, others = get_audio_datasets(
    "step2_prepare_training_sources/data/cicada_song/train",
    "step2_prepare_training_sources/data/background/preprocessed",
    "step2_prepare_training_sources/data/others"
)

if __name__ == "__main__":
    # Run example
    sr = 48000
    audio_sec = 30
    category_ratio = [0.7, 0.3]
                # Cicadas
    cicadas_to_use = ["aburazemi", "higurashi", "minminzemi", "niiniizemi", "tsukutsukuboushi"]
    cicada_weights = {"aburazemi": 1, "higurashi": 1, "minminzemi": 1,
                        "niiniizemi": 1, "tsukutsukuboushi": 1, }
    cicada_popsize_range = [1, 20]
    cicada_distance_range = [30, 60]
    cicada_species_range = [1, 4]
    # Other sounds
    others_weights = {"birds": 1, "esc50": 1, "insects": 1}
    others_popsize_range = [0, 20]
    others_distance_range = [10, 60]
    others_species_range = [1, 3]
    # Audio augmentation
    pitch_shift_range = None

    for i in range(100):
        generate(
            f"step3_model_training/data/train/audio/{i}.wav",
            f"step3_model_training/data/train/label/{i}.txt",
            cicadas, bgs, others, sr = sr, audio_sec = audio_sec, category_ratio = category_ratio,
            cicadas_to_use = cicadas_to_use, cicada_weights = cicada_weights, cicada_popsize_range = cicada_popsize_range,
            cicada_distance_range = cicada_distance_range, cicada_species_range = cicada_species_range,
            others_weights = others_weights, others_popsize_range = others_popsize_range,
            others_distance_range = others_distance_range, others_species_range = others_species_range,
            pitch_shift_range = pitch_shift_range, device="cpu")